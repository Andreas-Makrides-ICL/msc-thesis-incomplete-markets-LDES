{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58d73c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_4224\\1809242341.py:34: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  pv_df = pv_df.groupby('year').apply(filter_leap_year).reset_index(drop=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_4224\\1809242341.py:35: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  wind_df = wind_df.groupby('year').apply(filter_leap_year).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year,hour_of_year,PV,Wind\n",
      "1980,1.0,0.0,0.2858\n",
      "1980,2.0,0.0,0.2827\n",
      "1980,3.0,0.0,0.2852\n",
      "1980,4.0,0.0,0.292\n",
      "1980,5.0,0.0,0.3039\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Parameters\n",
    "pv_file = 'data\\\\ninja_pv_country_GB_merra-2_corrected (1).csv'\n",
    "wind_file = 'data\\\\ninja_wind_country_GB_current-merra-2_corrected.csv'\n",
    "output_file = 'processed_pv_wind.csv'\n",
    "\n",
    "# Read PV data, skipping header rows\n",
    "pv_df = pd.read_csv(pv_file, skiprows=2)\n",
    "\n",
    "# Read Wind data, selecting only time and onshore columns\n",
    "wind_df = pd.read_csv(wind_file, skiprows=2, usecols=['time', 'offshore'])\n",
    "\n",
    "# Convert time to datetime, explicitly setting UTC timezone\n",
    "pv_df['time'] = pd.to_datetime(pv_df['time'], utc=True)\n",
    "wind_df['time'] = pd.to_datetime(wind_df['time'], utc=True)\n",
    "\n",
    "# Extract year\n",
    "pv_df['year'] = pv_df['time'].dt.year\n",
    "wind_df['year'] = wind_df['time'].dt.year\n",
    "\n",
    "# Calculate hour of the year (hours since start of year)\n",
    "pv_df['hour_of_year'] = (pv_df['time'] - pd.to_datetime(pv_df['year'].astype(str) + '-01-01', utc=True)).dt.total_seconds() / 3600\n",
    "wind_df['hour_of_year'] = (wind_df['time'] - pd.to_datetime(wind_df['year'].astype(str) + '-01-01', utc=True)).dt.total_seconds() / 3600\n",
    "\n",
    "# Remove last day of leap years (hours >= 8760)\n",
    "def filter_leap_year(df_year):\n",
    "    year = df_year['year'].iloc[0]\n",
    "    is_leap = (year % 4 == 0 and year % 100 != 0) or (year % 400 == 0)\n",
    "    if is_leap:\n",
    "        return df_year[df_year['hour_of_year'] < 8760]\n",
    "    return df_year\n",
    "\n",
    "pv_df = pv_df.groupby('year').apply(filter_leap_year).reset_index(drop=True)\n",
    "wind_df = wind_df.groupby('year').apply(filter_leap_year).reset_index(drop=True)\n",
    "\n",
    "# Rename columns\n",
    "pv_df = pv_df[['year', 'hour_of_year', 'national']].rename(columns={'national': 'PV'})\n",
    "wind_df = wind_df[['year', 'hour_of_year', 'offshore']].rename(columns={'offshore': 'Wind'})\n",
    "\n",
    "# Merge PV and Wind data on year and hour_of_year\n",
    "merged_df = pd.merge(pv_df, wind_df, on=['year', 'hour_of_year'], how='inner')\n",
    "\n",
    "# Handle missing or invalid data\n",
    "merged_df = merged_df.dropna()\n",
    "merged_df = merged_df[\n",
    "    merged_df['PV'].notnull() & merged_df['PV'].apply(lambda x: isinstance(x, (int, float))) &\n",
    "    merged_df['Wind'].notnull() & merged_df['Wind'].apply(lambda x: isinstance(x, (int, float)))\n",
    "]\n",
    "\n",
    "merged_df[\"hour_of_year\"] = merged_df[\"hour_of_year\"]+1\n",
    "\n",
    "# Save to CSV\n",
    "merged_df.to_csv(output_file, index=False)\n",
    "\n",
    "# Print the first few rows for verification\n",
    "print(merged_df.head().to_csv(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4020338",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = merged_df['year'].unique()[-40:]\n",
    "filtered_df = merged_df[merged_df['year'].isin(years)]\n",
    "filtered_df.to_csv('data_VRE_40offshore.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
